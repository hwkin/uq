{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c6930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/neuralop/lib/python3.12/site-packages/ufl/__init__.py:250: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import dolfin as dl\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "src_path = \"../src/\"\n",
    " \n",
    "sys.path.append(src_path + 'pde/')\n",
    "from meshUtilities import get_dirichlet_bc, get_grid_dirichlet_bc # pyright: ignore[reportMissingImports]\n",
    "\n",
    "sys.path.append(src_path + 'prior/')\n",
    "from priorSampler import PriorSampler # pyright: ignore[reportMissingImports]\n",
    "\n",
    "from poissonModel import PoissonModel\n",
    "\n",
    "sys.path.append(src_path + 'data/')\n",
    "from dataMethods import DataProcessor # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# set seed\n",
    "seed = 1024\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "data_folder = '../../autodl-tmp/data/'\n",
    "results_dir = data_folder\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For training\n",
    "data_setting = ['',0.005,0.2,1,0]\n",
    " \n",
    "name = data_setting[0]\n",
    "print('Generating data set: {}'.format(name))\n",
    "prior_ac = data_setting[1]\n",
    "prior_cc = data_setting[2]\n",
    "prior_logn_scale = data_setting[3]\n",
    "prior_logn_translate = data_setting[4]\n",
    "nx, ny = 50, 50\n",
    "fe_order = 1\n",
    "data_prefix = 'Poisson'\n",
    "\n",
    "# create mesh\n",
    "mesh = dl.UnitSquareMesh(nx, ny)\n",
    "\n",
    "# create function spaces\n",
    "Vm = dl.FunctionSpace(mesh, 'Lagrange', fe_order)\n",
    "Vu = Vm\n",
    "\n",
    "# create prior sampler\n",
    "prior_sampler = PriorSampler(Vm, prior_ac, prior_cc, seed)\n",
    "\n",
    "# create model\n",
    "model = PoissonModel(Vm, Vu, prior_sampler, prior_logn_scale, prior_logn_translate, seed)\n",
    "\n",
    "num_samples = 5000\n",
    "\n",
    "w_samples = np.zeros((num_samples, model.m_dim))\n",
    "m_samples = np.zeros((num_samples, model.m_dim))\n",
    "u_samples = np.zeros((num_samples, model.u_dim))\n",
    "\n",
    "w, m, u = model.empty_m(), model.empty_m(), model.empty_u()\n",
    "\n",
    "for i in range(num_samples):\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    # draw from gaussian prior\n",
    "    if i == 0:\n",
    "        w = prior_sampler.mean.copy()\n",
    "    else:\n",
    "        w = prior_sampler(w)[0]\n",
    "    \n",
    "    # transform w to m\n",
    "    m = model.transform_gaussian_pointwise(w, m)\n",
    "    \n",
    "    # if m is transformed above, we do not need to transform it again\n",
    "    u = model.solveFwd(u, m, transform_m = False)\n",
    "\n",
    "    # save\n",
    "    w_samples[i, :] = w\n",
    "    m_samples[i, :] = m\n",
    "    u_samples[i, :] = u\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    sample_time = end_time - start_time\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('Sample {:4d} took {:.3f} seconds'.format(i, sample_time))\n",
    "\n",
    "print(m_samples.shape, m_samples.shape, u_samples.shape)\n",
    "\n",
    "proj_w_dim, proj_m_dim, proj_u_dim = 100, 100, 100\n",
    "tol = 1.e-9\n",
    "w_mean = np.mean(w_samples, axis = 0)\n",
    "m_mean = np.mean(m_samples, axis = 0)\n",
    "u_mean = np.mean(u_samples, axis = 0)\n",
    "w_std = np.std(w_samples, axis = 0)\n",
    "m_std = np.std(m_samples, axis = 0)\n",
    "u_std = np.std(u_samples, axis = 0)\n",
    "w_normalized = (w_samples - w_mean) / (w_std + tol)\n",
    "m_normalized = (m_samples - m_mean) / (m_std + tol)\n",
    "u_normalized = (u_samples - u_mean) / (u_std + tol)\n",
    "w_SVD, w_s, _ = np.linalg.svd(w_normalized.T, full_matrices = False)\n",
    "m_SVD, m_s, _ = np.linalg.svd(m_normalized.T, full_matrices = False)\n",
    "u_SVD, u_s, _ = np.linalg.svd(u_normalized.T, full_matrices = False)\n",
    "\n",
    "u_mesh_dirichlet_boundary_nodes = get_dirichlet_bc(model.is_point_on_dirichlet_boundary, model.u_nodes)\n",
    "np.savez(results_dir + data_prefix + f'_samples_{name}.npz', \\\n",
    "        w_samples = w_samples, \\\n",
    "        m_samples = m_samples, \\\n",
    "        u_samples = u_samples, \\\n",
    "        num_samples = num_samples, \\\n",
    "        m_dim = model.m_dim, u_dim = model.u_dim, \\\n",
    "        fe_order = fe_order, \\\n",
    "        nx = nx, ny = ny, \\\n",
    "        prior_ac = prior_ac, \\\n",
    "        prior_cc = prior_cc, \\\n",
    "        prior_alpham = prior_logn_scale, \\\n",
    "        prior_betam = prior_logn_translate, \\\n",
    "        u_mesh_nodes = model.u_nodes, \\\n",
    "        m_mesh_nodes = model.m_nodes, \\\n",
    "        u_mesh_elements = model.Vu.mesh().cells(), \\\n",
    "        m_mesh_elements = model.Vm.mesh().cells(), \\\n",
    "        u_mesh_dirichlet_boundary_nodes = u_mesh_dirichlet_boundary_nodes, \\\n",
    "        w_SVD = w_SVD, w_s = w_s, \\\n",
    "        m_SVD = m_SVD, m_s = m_s, \\\n",
    "        u_SVD = u_SVD, u_s = u_s\n",
    "        )\n",
    "\n",
    "num_grid_x, num_grid_y = 51, 51\n",
    "print('Generating FNO data for grid sizes ({}, {})'.format(num_grid_x, num_grid_y))\n",
    "\n",
    "# get grid coordinates\n",
    "grid_x, grid_y = np.meshgrid(np.linspace(0, 1, num_grid_x), np.linspace(0, 1, num_grid_y), indexing='ij')\n",
    "\n",
    "# load data\n",
    "data_load = np.load(results_dir + data_prefix + f'_samples_{name}.npz')\n",
    "\n",
    "m_nodes = data_load['m_mesh_nodes']\n",
    "u_nodes = data_load['u_mesh_nodes']\n",
    "\n",
    "w_samples = data_load['w_samples']\n",
    "m_samples = data_load['m_samples']\n",
    "u_samples = data_load['u_samples']\n",
    "\n",
    "num_samples = m_samples.shape[0]\n",
    "\n",
    "# get indices of grid points on the boundary\n",
    "u_grid_dirichlet_boundary_nodes = get_grid_dirichlet_bc(model.is_point_on_dirichlet_boundary, grid_x, grid_y)\n",
    "\n",
    "# interpolate samples on grid\n",
    "grid_w_samples = np.zeros((num_samples, num_grid_x, num_grid_y))\n",
    "grid_m_samples = np.zeros((num_samples, num_grid_x, num_grid_y))\n",
    "grid_u_samples = np.zeros((num_samples, num_grid_x, num_grid_y))\n",
    "for i in range(num_samples):\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    grid_w_samples[i, :, :] = griddata(m_nodes, w_samples[i, :], (grid_x, grid_y), method='linear')\n",
    "    grid_m_samples[i, :, :] = griddata(m_nodes, m_samples[i, :], (grid_x, grid_y), method='linear')\n",
    "    grid_u_samples[i, :, :] = griddata(u_nodes, u_samples[i, :], (grid_x, grid_y), method='linear')\n",
    "\n",
    "    # explicity set boundary points to zero (not necessary as the solution of PDE is zero on the boundary)\n",
    "    grid_u_samples[i, u_grid_dirichlet_boundary_nodes[:,0], u_grid_dirichlet_boundary_nodes[:,1]] = 0.0\n",
    "\n",
    "    end_time = time.perf_counter()\n",
    "    sample_time = end_time - start_time\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print('Sample {:4d} took {:.3f} seconds'.format(i, sample_time))\n",
    "\n",
    "print(grid_m_samples.shape, grid_u_samples.shape)\n",
    "\n",
    "np.savez(results_dir + data_prefix + f'_FNO_samples_{name}.npz', \\\n",
    "        grid_w_samples = grid_w_samples, \\\n",
    "        grid_m_samples = grid_m_samples, \\\n",
    "        grid_u_samples = grid_u_samples, \\\n",
    "        num_samples = num_samples, \\\n",
    "        num_grid_x = num_grid_x, num_grid_y = num_grid_y, \\\n",
    "        grid_x = grid_x, grid_y = grid_y, \\\n",
    "        u_grid_dirichlet_boundary_nodes = u_grid_dirichlet_boundary_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7ef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data set: ood-0.1\n",
      "(500, 2601) (500, 2601) (500, 2601)\n",
      "Generating FNO data for grid sizes (51, 51)\n",
      "Generating data set: ood-0.2\n",
      "(500, 2601) (500, 2601) (500, 2601)\n",
      "Generating FNO data for grid sizes (51, 51)\n",
      "Generating data set: ood-0.4\n",
      "(500, 2601) (500, 2601) (500, 2601)\n",
      "Generating FNO data for grid sizes (51, 51)\n",
      "Generating data set: ood-0.8\n",
      "(500, 2601) (500, 2601) (500, 2601)\n",
      "Generating FNO data for grid sizes (51, 51)\n",
      "Generating data set: ood-1.6\n",
      "(500, 2601) (500, 2601) (500, 2601)\n",
      "Generating FNO data for grid sizes (51, 51)\n",
      "Generating data set: ood--0.1\n",
      "(500, 2601) (500, 2601) (500, 2601)\n",
      "Generating FNO data for grid sizes (51, 51)\n"
     ]
    }
   ],
   "source": [
    "data_type=[['no-ood',0.005,0.2,1,0],['ood-1',0.005,0.2,1,0.03],['ood-2',0.005,0.2,1,0.06],\\\n",
    "           ['ood-3',0.005,0.2,1,0.1],['ood-4',0.005,0.2,1,0.15],['ood-5',0.005,0.2,1,0.2], \\\n",
    "            ['ood-6',0.005,0.2,1,-0.2]]\n",
    "#1st is for verifying ood detection and used as id data; 2-6th are shifting data and 7th is wrongly sampled (m(x) must be positive in physics)\n",
    "for data_setting in data_type:\n",
    "    name = data_setting[0]\n",
    "    print('Generating data set: {}'.format(name))\n",
    "    prior_ac = data_setting[1]\n",
    "    prior_cc = data_setting[2]\n",
    "    prior_logn_scale = data_setting[3]\n",
    "    prior_logn_translate = data_setting[4]\n",
    "    nx, ny = 50, 50\n",
    "    fe_order = 1\n",
    "    data_prefix = 'Poisson'\n",
    "\n",
    "    # create mesh\n",
    "    mesh = dl.UnitSquareMesh(nx, ny)\n",
    "\n",
    "    # create function spaces\n",
    "    Vm = dl.FunctionSpace(mesh, 'Lagrange', fe_order)\n",
    "    Vu = Vm\n",
    "\n",
    "    # create prior sampler\n",
    "    prior_sampler = PriorSampler(Vm, prior_ac, prior_cc, seed)\n",
    "\n",
    "    # create model\n",
    "    model = PoissonModel(Vm, Vu, prior_sampler, prior_logn_scale, prior_logn_translate, seed)\n",
    "    num_samples = 500\n",
    "\n",
    "    w_sample = np.zeros((num_samples, model.m_dim))\n",
    "    m_sample = np.zeros((num_samples, model.m_dim))\n",
    "    u_sample = np.zeros((num_samples, model.u_dim))\n",
    "\n",
    "    w, m, u = model.empty_m(), model.empty_m(), model.empty_u()\n",
    "\n",
    "    for i in range(num_samples):\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # draw from gaussian prior\n",
    "        if i == 0:\n",
    "            w = prior_sampler.mean.copy()\n",
    "        else:\n",
    "            w = prior_sampler(w)[0]\n",
    "        \n",
    "        # transform w to m\n",
    "        m = model.transform_gaussian_pointwise(w, m)\n",
    "        \n",
    "        # if m is transformed above, we do not need to transform it again\n",
    "        u = model.solveFwd(u, m, transform_m = False)\n",
    "\n",
    "        # save\n",
    "        w_sample[i, :] = w\n",
    "        m_sample[i, :] = m\n",
    "        u_sample[i, :] = u\n",
    "\n",
    "    print(m_sample.shape, m_sample.shape, u_sample.shape)\n",
    "    w_samples = np.array([])  # re-initialize to avoid accumulation\n",
    "    m_samples = np.array([])\n",
    "    u_samples = np.array([])\n",
    "    w_samples = np.concatenate((w_samples, w_sample), axis=0) if len(w_samples) else w_sample\n",
    "    m_samples = np.concatenate((m_samples, m_sample), axis=0) if len(m_samples) else m_sample\n",
    "    u_samples = np.concatenate((u_samples, u_sample), axis=0) if len(u_samples) else u_sample\n",
    "\n",
    "    proj_w_dim, proj_m_dim, proj_u_dim = 100, 100, 100\n",
    "    tol = 1.e-9\n",
    "    w_mean = np.mean(w_samples, axis = 0)\n",
    "    m_mean = np.mean(m_samples, axis = 0)\n",
    "    u_mean = np.mean(u_samples, axis = 0)\n",
    "    w_std = np.std(w_samples, axis = 0)\n",
    "    m_std = np.std(m_samples, axis = 0)\n",
    "    u_std = np.std(u_samples, axis = 0)\n",
    "    w_normalized = (w_samples - w_mean) / (w_std + tol)\n",
    "    m_normalized = (m_samples - m_mean) / (m_std + tol)\n",
    "    u_normalized = (u_samples - u_mean) / (u_std + tol)\n",
    "    w_SVD, w_s, _ = np.linalg.svd(w_normalized.T, full_matrices = False)\n",
    "    m_SVD, m_s, _ = np.linalg.svd(m_normalized.T, full_matrices = False)\n",
    "    u_SVD, u_s, _ = np.linalg.svd(u_normalized.T, full_matrices = False)\n",
    "\n",
    "    u_mesh_dirichlet_boundary_nodes = get_dirichlet_bc(model.is_point_on_dirichlet_boundary, model.u_nodes)\n",
    "    np.savez(results_dir + data_prefix + f'_samples_{name}.npz', \\\n",
    "            w_samples = w_samples, \\\n",
    "            m_samples = m_samples, \\\n",
    "            u_samples = u_samples, \\\n",
    "            num_samples = num_samples, \\\n",
    "            m_dim = model.m_dim, u_dim = model.u_dim, \\\n",
    "            fe_order = fe_order, \\\n",
    "            nx = nx, ny = ny, \\\n",
    "            u_mesh_nodes = model.u_nodes, \\\n",
    "            m_mesh_nodes = model.m_nodes, \\\n",
    "            u_mesh_elements = model.Vu.mesh().cells(), \\\n",
    "            m_mesh_elements = model.Vm.mesh().cells(), \\\n",
    "            u_mesh_dirichlet_boundary_nodes = u_mesh_dirichlet_boundary_nodes, \\\n",
    "            w_SVD = w_SVD, w_s = w_s, \\\n",
    "            m_SVD = m_SVD, m_s = m_s, \\\n",
    "            u_SVD = u_SVD, u_s = u_s\n",
    "            )\n",
    "\n",
    "    num_grid_x, num_grid_y = 51, 51\n",
    "    print('Generating FNO data for grid sizes ({}, {})'.format(num_grid_x, num_grid_y))\n",
    "\n",
    "    # get grid coordinates\n",
    "    grid_x, grid_y = np.meshgrid(np.linspace(0, 1, num_grid_x), np.linspace(0, 1, num_grid_y), indexing='ij')\n",
    "\n",
    "    # load data\n",
    "    data_load = np.load(results_dir + data_prefix + f'_samples_{name}.npz')\n",
    "\n",
    "    m_nodes = data_load['m_mesh_nodes']\n",
    "    u_nodes = data_load['u_mesh_nodes'] \n",
    "\n",
    "    w_samples = data_load['w_samples']\n",
    "    m_samples = data_load['m_samples']\n",
    "    u_samples = data_load['u_samples']\n",
    "\n",
    "    num_samples = m_samples.shape[0]\n",
    "\n",
    "    # get indices of grid points on the boundary\n",
    "    u_grid_dirichlet_boundary_nodes = get_grid_dirichlet_bc(model.is_point_on_dirichlet_boundary, grid_x, grid_y)\n",
    "\n",
    "    # interpolate samples on grid\n",
    "    grid_w_samples = np.zeros((num_samples, num_grid_x, num_grid_y))\n",
    "    grid_m_samples = np.zeros((num_samples, num_grid_x, num_grid_y))\n",
    "    grid_u_samples = np.zeros((num_samples, num_grid_x, num_grid_y))\n",
    "    for i in range(num_samples):\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        grid_w_samples[i, :, :] = griddata(m_nodes, w_samples[i, :], (grid_x, grid_y), method='linear')\n",
    "        grid_m_samples[i, :, :] = griddata(m_nodes, m_samples[i, :], (grid_x, grid_y), method='linear')\n",
    "        grid_u_samples[i, :, :] = griddata(u_nodes, u_samples[i, :], (grid_x, grid_y), method='linear')\n",
    "\n",
    "        # explicity set boundary points to zero (not necessary as the solution of PDE is zero on the boundary)\n",
    "        grid_u_samples[i, u_grid_dirichlet_boundary_nodes[:,0], u_grid_dirichlet_boundary_nodes[:,1]] = 0.0\n",
    "\n",
    "        end_time = time.perf_counter()\n",
    "        sample_time = end_time - start_time\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('Sample {:4d} took {:.3f} seconds'.format(i, sample_time))\n",
    "\n",
    "    print(grid_m_samples.shape, grid_u_samples.shape)\n",
    "\n",
    "    np.savez(results_dir + data_prefix + f'_FNO_samples_{name}.npz', \\\n",
    "            grid_w_samples = grid_w_samples, \\\n",
    "            grid_m_samples = grid_m_samples, \\\n",
    "            grid_u_samples = grid_u_samples, \\\n",
    "            num_samples = num_samples, \\\n",
    "            num_grid_x = num_grid_x, num_grid_y = num_grid_y, \\\n",
    "            grid_x = grid_x, grid_y = grid_y, \\\n",
    "            u_grid_dirichlet_boundary_nodes = u_grid_dirichlet_boundary_nodes)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
